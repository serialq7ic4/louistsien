---
{"dg-publish":true,"permalink":"/部署实施/"}
---

# 新集群建设

新集群建设始终以 3 台需要部署 Monitor 服务的服务器展开，如果存在超过除 Monitor 角色以外的服务器需要部署 OSD 服务，则直接执行添加 OSD 步骤即可。

## 初始化 ceph 配置目录

创建集群目录，用于维护 ceph-deploy 为集群生成的配置文件和密钥

```shell
su godfather
mkdir ~/cephdeploy && cd ~/cephdeploy
```

在 cephdeploy 目录下执行初始化集群配置

```shell
ceph-deploy new $(hostname -s) $(hostname -s | sed 's/.$/2/g') $(hostname -s | sed 's/.$/3/g')
```

## 修改配置

```shell
curl http://10.103.251.43/files/ceph_deploy_conf_format.sh | bash
```

## ceph 包安装

```shell
ceph-deploy install --repo-url http://10.103.251.43/files/ceph/rpm-jewel/el7/
```

## 部署 mon 服务

```shell
ceph-deploy mon create-initial
```

同步配置文件，到所有节点

```shell
ceph-deploy admin $(hostname -s) $(hostname -s | sed 's/.$/2/g') $(hostname -s | sed 's/.$/3/g')
```

## 部署 mgr 服务

```shell
ceph-deploy mgr create $(hostname -s) $(hostname -s | sed 's/.$/2/g') $(hostname -s | sed 's/.$/3/g')
```

## 部署 osd 服务

### 格式化分区

> 适用于 12+2 [[软硬件选型#平衡型\|平衡型服务器]]，其他平衡型配置需要调整脚本

```shell
curl http://10.103.251.43/files/parted_nvme.sh | bash
```

### 初始化缓存服务

```shell
casadm -S -d /dev/nvme0n1p7 -c wb 
casadm -S -d /dev/nvme1n1p7 -c wb
```

### 创建 OSD 服务

> 主机名替换为待部署 OSD 服务器的 hostname -s 命令结果
> 部署 OSD 的硬盘为裸盘，sdb、sdc...
> 部署 WALDB 的硬盘为 SATA SSD 时，分区参考 sdk1、sdk2...
> 部署 WALDB 的硬盘为 NVME SSD 时，分区参考 nvme0n1p1、nvme0n1p2...

```shell
ceph-deploy osd create 主机名 --data /dev/部署OSD的硬盘 --block-db /dev/部署WALDB的SSD分区
```

### OSD 硬盘绑定缓存

```shell
#!/bin/bash
for osd in `df -h | grep ceph | awk -F- '{print $NF}' | head -n6`
do
systemctl stop ceph-osd@$osd
umount /var/lib/ceph/osd/ceph-$osd
osdid=`ceph osd dump|grep osd.|awk -v  A=osd.$osd '{if($1==A) print $19}'`
systemctl disable ceph-volume@lvm-$osd-$osdid
systemctl disable ceph-osd@$osd
osdpathprefix=`echo $osdid|cut -d "-" -f 1`
osdpath=`ls /dev/mapper/ceph--*|grep $osdpathprefix`
casadm -A  -d $osdpath -i 1 -j $osd
echo "1           $osd            $osdpath"
done
for osd in `df -h | grep ceph | awk -F- '{print $NF}' | tail -n6`
do
systemctl stop ceph-osd@$osd
umount /var/lib/ceph/osd/ceph-$osd
osdid=`ceph osd dump|grep osd.|awk -v  A=osd.$osd '{if($1==A) print $19}'`
systemctl disable ceph-volume@lvm-$osd-$osdid
systemctl disable ceph-osd@$osd
osdpathprefix=`echo $osdid|cut -d "-" -f 1`
osdpath=`ls /dev/mapper/ceph--*|grep $osdpathprefix`
casadm -A  -d $osdpath -i 1 -j $osd
echo "2           $osd            $osdpath"
done
```

会输出几行对应关系，拷贝到配置文件 `/etc/intelcas/intelcas.conf`

### 启动脚本

 ```bash
#! /bin/sh
# start osd.5 osd.8 osd.11
for osd in ``df -h | grep ceph | awk -F- '{print $NF}'`
do
mount -t tmpfs tmpfs /var/lib/ceph/osd/ceph-$osd
restorecon /var/lib/ceph/osd/ceph-$osd
chown -R ceph:ceph /var/lib/ceph/osd/ceph-$osd
ceph-bluestore-tool --cluster=ceph prime-osd-dir --dev /dev/intelcas1-$osd --path /var/lib/ceph/osd/ceph-$osd --no-mon-config
ln -snf ${INTELCAS_NAME} ${CEPH_OSD_PATH}/ceph-$OSD_NUM/block
chown -h ceph:ceph /var/lib/ceph/osd/ceph-$osd/block
chown -R ceph:ceph /dev/cas1-$osd
chown -R ceph:ceph /var/lib/ceph/osd/ceph-$osd
systemctl start ceph-osd@$osd
done
```